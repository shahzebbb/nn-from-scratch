{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autodiff import Value\n",
    "from autodiff.nn import *\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mnist (C:/Users/shahz/.cache/huggingface/datasets/mnist/mnist/1.0.0/9d494b7f466d6931c64fb39d58bb1249a4d85c9eb9865d9bc20960b999e2a332)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefaccb49e9a43c6bb293867a043350f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (60000, 2)\n",
      "Testing dataset shape: (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_dataset = load_dataset('mnist')\n",
    "\n",
    "# Access the training and testing datasets\n",
    "train_dataset = mnist_dataset['train']\n",
    "test_dataset = mnist_dataset['test']\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(f'Training dataset shape: {train_dataset.shape}')\n",
    "print(f'Testing dataset shape: {test_dataset.shape}')\n",
    "\n",
    "def preprocess_image(img):\n",
    "    array = np.array(img)\n",
    "    flat_array = array.reshape(-1)\n",
    "    flat_array = flat_array / 255\n",
    "    flat_array = list(flat_array)\n",
    "    return flat_array\n",
    "\n",
    "X_train = list(map(lambda x: preprocess_image(x['image']), train_dataset))[:1000]\n",
    "y_train = [x['label'] for x in train_dataset][:1000]\n",
    "\n",
    "\n",
    "X_test = list(map(lambda x: preprocess_image(x['image']), test_dataset))[:1000]\n",
    "y_test = [x['label'] for x in test_dataset][:1000]\n",
    "\n",
    "#Shuffle the training data\n",
    "combined = list(zip(X_train, y_train))\n",
    "random.shuffle(combined)\n",
    "X_train, y_train = zip(*combined)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model and performing training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(28*28, [32,32,10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define softmax and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    exp_logits = [value.exp() for value in logits]\n",
    "    total = sum(exp_logits)\n",
    "    return [(value/total) for value in exp_logits]\n",
    "\n",
    "    \n",
    "def cross_entropy_loss(predictions, label):\n",
    "    return -1 *softmax(predictions)[label].log()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "Step 1\n",
      "Loss for this step: Value(data=84.71208311638756, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 2\n",
      "Loss for this step: Value(data=40.986077433061695, grad=0)\n",
      "Accuracy: 0.0\n",
      "Step 3\n",
      "Loss for this step: Value(data=27.75498087343429, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 4\n",
      "Loss for this step: Value(data=19.618400661264513, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 5\n",
      "Loss for this step: Value(data=23.156014555738558, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 6\n",
      "Loss for this step: Value(data=25.18481063545945, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 7\n",
      "Loss for this step: Value(data=19.129943130482598, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 8\n",
      "Loss for this step: Value(data=15.581019968023845, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 9\n",
      "Loss for this step: Value(data=22.50501469644824, grad=0)\n",
      "Accuracy: 0.0\n",
      "Step 10\n",
      "Loss for this step: Value(data=12.351369004797835, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 11\n",
      "Loss for this step: Value(data=16.627393790000674, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 12\n",
      "Loss for this step: Value(data=12.735803251335003, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 13\n",
      "Loss for this step: Value(data=9.759748797934442, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 14\n",
      "Loss for this step: Value(data=18.895794617917165, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 15\n",
      "Loss for this step: Value(data=12.658147321099035, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 16\n",
      "Loss for this step: Value(data=12.803454155886925, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 17\n",
      "Loss for this step: Value(data=15.942729352047692, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 18\n",
      "Loss for this step: Value(data=12.259946414047263, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 19\n",
      "Loss for this step: Value(data=20.167231045340976, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 20\n",
      "Loss for this step: Value(data=10.376403272472011, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 21\n",
      "Loss for this step: Value(data=12.243439771634558, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 22\n",
      "Loss for this step: Value(data=10.335868387231598, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 23\n",
      "Loss for this step: Value(data=12.711349657007306, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 24\n",
      "Loss for this step: Value(data=13.418855864044382, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 25\n",
      "Loss for this step: Value(data=15.111728598890977, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 26\n",
      "Loss for this step: Value(data=17.946103426471407, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 27\n",
      "Loss for this step: Value(data=8.856247179497116, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 28\n",
      "Loss for this step: Value(data=10.369973599590368, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 29\n",
      "Loss for this step: Value(data=13.480753054357757, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 30\n",
      "Loss for this step: Value(data=8.601765772855247, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 31\n",
      "Loss for this step: Value(data=14.38319987388416, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 32\n",
      "Loss for this step: Value(data=13.207611780097121, grad=0)\n",
      "Accuracy: 0.0\n",
      "Step 33\n",
      "Loss for this step: Value(data=9.373482301686344, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 34\n",
      "Loss for this step: Value(data=13.998170154090703, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 35\n",
      "Loss for this step: Value(data=10.877472589508262, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 36\n",
      "Loss for this step: Value(data=13.405484514728363, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 37\n",
      "Loss for this step: Value(data=7.283236213340646, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 38\n",
      "Loss for this step: Value(data=11.266945448135415, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 39\n",
      "Loss for this step: Value(data=12.703714695174193, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 40\n",
      "Loss for this step: Value(data=8.413763423501875, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 41\n",
      "Loss for this step: Value(data=11.900272806273888, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 42\n",
      "Loss for this step: Value(data=13.384045153675341, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 43\n",
      "Loss for this step: Value(data=5.2514018230109, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 44\n",
      "Loss for this step: Value(data=7.324943066647122, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 45\n",
      "Loss for this step: Value(data=6.839322808446735, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 46\n",
      "Loss for this step: Value(data=11.085082102994145, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 47\n",
      "Loss for this step: Value(data=6.62017029753017, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 48\n",
      "Loss for this step: Value(data=10.881065219854099, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 49\n",
      "Loss for this step: Value(data=7.413448949255635, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 50\n",
      "Loss for this step: Value(data=8.180892567662651, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 51\n",
      "Loss for this step: Value(data=7.265846884185991, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 52\n",
      "Loss for this step: Value(data=9.033810041231334, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 53\n",
      "Loss for this step: Value(data=8.699714034141673, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 54\n",
      "Loss for this step: Value(data=10.080885908002596, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 55\n",
      "Loss for this step: Value(data=10.272428983280601, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 56\n",
      "Loss for this step: Value(data=11.41682105004496, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 57\n",
      "Loss for this step: Value(data=7.303114663196615, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 58\n",
      "Loss for this step: Value(data=6.613777570572098, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 59\n",
      "Loss for this step: Value(data=5.885201339325713, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 60\n",
      "Loss for this step: Value(data=6.667470613204427, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 61\n",
      "Loss for this step: Value(data=6.928889628051609, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 62\n",
      "Loss for this step: Value(data=4.785661820985972, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 63\n",
      "Loss for this step: Value(data=11.086026115321037, grad=0)\n",
      "Accuracy: 0.125\n",
      "Epoch:2\n",
      "Step 1\n",
      "Loss for this step: Value(data=6.142289757262475, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 2\n",
      "Loss for this step: Value(data=5.174437087238393, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 3\n",
      "Loss for this step: Value(data=8.647986825697894, grad=0)\n",
      "Accuracy: 0.0\n",
      "Step 4\n",
      "Loss for this step: Value(data=7.3720422436873125, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 5\n",
      "Loss for this step: Value(data=7.998547349878123, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 6\n",
      "Loss for this step: Value(data=4.3459230201094, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 7\n",
      "Loss for this step: Value(data=3.759421138835954, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 8\n",
      "Loss for this step: Value(data=9.839384517933873, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 9\n",
      "Loss for this step: Value(data=7.637363826996497, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 10\n",
      "Loss for this step: Value(data=6.461507979002758, grad=0)\n",
      "Accuracy: 0.0\n",
      "Step 11\n",
      "Loss for this step: Value(data=3.510642239219306, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 12\n",
      "Loss for this step: Value(data=7.571462259232428, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 13\n",
      "Loss for this step: Value(data=5.86673420122093, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 14\n",
      "Loss for this step: Value(data=4.450937120353323, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 15\n",
      "Loss for this step: Value(data=5.608856314632744, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 16\n",
      "Loss for this step: Value(data=4.3743755558458215, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 17\n",
      "Loss for this step: Value(data=7.405885966551651, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 18\n",
      "Loss for this step: Value(data=2.4144081447100483, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 19\n",
      "Loss for this step: Value(data=4.193507636076822, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 20\n",
      "Loss for this step: Value(data=6.696188824444611, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 21\n",
      "Loss for this step: Value(data=6.970799385373292, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 22\n",
      "Loss for this step: Value(data=6.77807854655745, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 23\n",
      "Loss for this step: Value(data=7.98285910118949, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 24\n",
      "Loss for this step: Value(data=5.188396375379819, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 25\n",
      "Loss for this step: Value(data=4.228327634682282, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 26\n",
      "Loss for this step: Value(data=4.57226330289435, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 27\n",
      "Loss for this step: Value(data=5.660356726448607, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 28\n",
      "Loss for this step: Value(data=9.307003448601504, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 29\n",
      "Loss for this step: Value(data=5.5297413140320275, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 30\n",
      "Loss for this step: Value(data=3.1064603032355937, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 31\n",
      "Loss for this step: Value(data=6.404759717897366, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 32\n",
      "Loss for this step: Value(data=6.488298931078916, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 33\n",
      "Loss for this step: Value(data=8.597767902765431, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 34\n",
      "Loss for this step: Value(data=6.423777104697779, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 35\n",
      "Loss for this step: Value(data=10.022448690037246, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 36\n",
      "Loss for this step: Value(data=7.796675998276146, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 37\n",
      "Loss for this step: Value(data=4.98092287412696, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 38\n",
      "Loss for this step: Value(data=6.2497725093868155, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 39\n",
      "Loss for this step: Value(data=3.0954047145419286, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 40\n",
      "Loss for this step: Value(data=5.706024174903028, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 41\n",
      "Loss for this step: Value(data=7.761356070012778, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 42\n",
      "Loss for this step: Value(data=6.140164098525618, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 43\n",
      "Loss for this step: Value(data=6.769195526648412, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 44\n",
      "Loss for this step: Value(data=5.416954124848598, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 45\n",
      "Loss for this step: Value(data=6.438246736971278, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 46\n",
      "Loss for this step: Value(data=3.716810512757707, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 47\n",
      "Loss for this step: Value(data=3.7353652643941158, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 48\n",
      "Loss for this step: Value(data=5.322558503022595, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 49\n",
      "Loss for this step: Value(data=4.387578125273796, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 50\n",
      "Loss for this step: Value(data=7.70683505081874, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 51\n",
      "Loss for this step: Value(data=7.491606774958085, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 52\n",
      "Loss for this step: Value(data=3.9108292725009592, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 53\n",
      "Loss for this step: Value(data=4.065857419263407, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 54\n",
      "Loss for this step: Value(data=6.60307916016109, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 55\n",
      "Loss for this step: Value(data=4.902860650951966, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 56\n",
      "Loss for this step: Value(data=4.85297874607725, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 57\n",
      "Loss for this step: Value(data=5.62571010996024, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 58\n",
      "Loss for this step: Value(data=5.7407594725174675, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 59\n",
      "Loss for this step: Value(data=5.467168813326245, grad=0)\n",
      "Accuracy: 0.0\n",
      "Step 60\n",
      "Loss for this step: Value(data=3.6478962960606833, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 61\n",
      "Loss for this step: Value(data=5.559875949476047, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 62\n",
      "Loss for this step: Value(data=4.320999540237324, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 63\n",
      "Loss for this step: Value(data=2.8832182029048217, grad=0)\n",
      "Accuracy: 0.5\n",
      "Epoch:3\n",
      "Step 1\n",
      "Loss for this step: Value(data=6.188177398169618, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 2\n",
      "Loss for this step: Value(data=6.000265276859796, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 3\n",
      "Loss for this step: Value(data=5.5725137887456695, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 4\n",
      "Loss for this step: Value(data=5.1677113047652545, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 5\n",
      "Loss for this step: Value(data=4.198455938781574, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 6\n",
      "Loss for this step: Value(data=4.842639541641566, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 7\n",
      "Loss for this step: Value(data=3.4060243402368764, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 8\n",
      "Loss for this step: Value(data=3.6109129155913817, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 9\n",
      "Loss for this step: Value(data=6.675270442107137, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 10\n",
      "Loss for this step: Value(data=6.3374444358426265, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 11\n",
      "Loss for this step: Value(data=3.633993525749826, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 12\n",
      "Loss for this step: Value(data=2.672098913910071, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 13\n",
      "Loss for this step: Value(data=5.419456664474366, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 14\n",
      "Loss for this step: Value(data=4.273658792243906, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 15\n",
      "Loss for this step: Value(data=3.5815274719424166, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 16\n",
      "Loss for this step: Value(data=3.553599365488732, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 17\n",
      "Loss for this step: Value(data=4.0630326756246635, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 18\n",
      "Loss for this step: Value(data=6.505271271024251, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 19\n",
      "Loss for this step: Value(data=4.1357826025845785, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 20\n",
      "Loss for this step: Value(data=4.786582269870183, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 21\n",
      "Loss for this step: Value(data=3.4292723485735292, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 22\n",
      "Loss for this step: Value(data=2.8414984789208177, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 23\n",
      "Loss for this step: Value(data=5.128869178576812, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 24\n",
      "Loss for this step: Value(data=5.142368403804878, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 25\n",
      "Loss for this step: Value(data=5.162459251140793, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 26\n",
      "Loss for this step: Value(data=4.426088835067003, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 27\n",
      "Loss for this step: Value(data=3.353101462549324, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 28\n",
      "Loss for this step: Value(data=6.468909925913053, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 29\n",
      "Loss for this step: Value(data=3.677899845169591, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 30\n",
      "Loss for this step: Value(data=1.7672744604867485, grad=0)\n",
      "Accuracy: 0.5625\n",
      "Step 31\n",
      "Loss for this step: Value(data=6.261250407570575, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 32\n",
      "Loss for this step: Value(data=3.1439232546628935, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 33\n",
      "Loss for this step: Value(data=5.310581827664111, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 34\n",
      "Loss for this step: Value(data=4.267153914007409, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 35\n",
      "Loss for this step: Value(data=5.407025992082813, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 36\n",
      "Loss for this step: Value(data=3.9714184378277224, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 37\n",
      "Loss for this step: Value(data=4.018309630266367, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 38\n",
      "Loss for this step: Value(data=2.981126012354289, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 39\n",
      "Loss for this step: Value(data=3.927759383017583, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 40\n",
      "Loss for this step: Value(data=4.0576316218138455, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 41\n",
      "Loss for this step: Value(data=5.284507181717394, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 42\n",
      "Loss for this step: Value(data=4.3844839177307, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 43\n",
      "Loss for this step: Value(data=6.118236295187781, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 44\n",
      "Loss for this step: Value(data=3.7438530394477474, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 45\n",
      "Loss for this step: Value(data=4.567607295100811, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 46\n",
      "Loss for this step: Value(data=6.9816719198200925, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 47\n",
      "Loss for this step: Value(data=2.796744755801631, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 48\n",
      "Loss for this step: Value(data=6.283072328284332, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 49\n",
      "Loss for this step: Value(data=5.66392485856486, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 50\n",
      "Loss for this step: Value(data=5.372750097474501, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 51\n",
      "Loss for this step: Value(data=5.127823465984007, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 52\n",
      "Loss for this step: Value(data=4.067356669811639, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 53\n",
      "Loss for this step: Value(data=6.160597151840362, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 54\n",
      "Loss for this step: Value(data=3.0302021637563166, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 55\n",
      "Loss for this step: Value(data=4.539840166529735, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 56\n",
      "Loss for this step: Value(data=4.695140576481276, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 57\n",
      "Loss for this step: Value(data=3.4447524688662776, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 58\n",
      "Loss for this step: Value(data=5.5494775412518695, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 59\n",
      "Loss for this step: Value(data=4.810589713106853, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 60\n",
      "Loss for this step: Value(data=2.952230929968988, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 61\n",
      "Loss for this step: Value(data=5.759937866651077, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 62\n",
      "Loss for this step: Value(data=2.692168555977885, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 63\n",
      "Loss for this step: Value(data=3.625872653809585, grad=0)\n",
      "Accuracy: 0.125\n",
      "Epoch:4\n",
      "Step 1\n",
      "Loss for this step: Value(data=3.126889630327289, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 2\n",
      "Loss for this step: Value(data=4.7540764623831775, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 3\n",
      "Loss for this step: Value(data=3.8164522300799724, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 4\n",
      "Loss for this step: Value(data=4.510163508619482, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 5\n",
      "Loss for this step: Value(data=4.786910305906572, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 6\n",
      "Loss for this step: Value(data=4.358566920012178, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 7\n",
      "Loss for this step: Value(data=2.840092670135084, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 8\n",
      "Loss for this step: Value(data=3.7659808683308658, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 9\n",
      "Loss for this step: Value(data=3.859517470796513, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 10\n",
      "Loss for this step: Value(data=4.027970156952205, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 11\n",
      "Loss for this step: Value(data=3.7352549389475245, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 12\n",
      "Loss for this step: Value(data=2.8572607526365266, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 13\n",
      "Loss for this step: Value(data=3.74071549064784, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 14\n",
      "Loss for this step: Value(data=4.788458753582221, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 15\n",
      "Loss for this step: Value(data=5.042433906273509, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 16\n",
      "Loss for this step: Value(data=4.063470733033627, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 17\n",
      "Loss for this step: Value(data=2.982198510497084, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 18\n",
      "Loss for this step: Value(data=5.061043438751645, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 19\n",
      "Loss for this step: Value(data=5.498839377838195, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 20\n",
      "Loss for this step: Value(data=2.45204638806831, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 21\n",
      "Loss for this step: Value(data=4.312155180228516, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 22\n",
      "Loss for this step: Value(data=4.3441769069294125, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 23\n",
      "Loss for this step: Value(data=2.6026076544031196, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 24\n",
      "Loss for this step: Value(data=2.3238745201303557, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 25\n",
      "Loss for this step: Value(data=2.863968557769658, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 26\n",
      "Loss for this step: Value(data=3.181495822092873, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 27\n",
      "Loss for this step: Value(data=1.6594582865764202, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 28\n",
      "Loss for this step: Value(data=4.860240665415391, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 29\n",
      "Loss for this step: Value(data=3.5650671548083226, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 30\n",
      "Loss for this step: Value(data=2.7624691138705537, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 31\n",
      "Loss for this step: Value(data=3.5834690608085453, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 32\n",
      "Loss for this step: Value(data=5.523489247994509, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 33\n",
      "Loss for this step: Value(data=5.415701577923472, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 34\n",
      "Loss for this step: Value(data=4.55806447008373, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 35\n",
      "Loss for this step: Value(data=6.356022104712846, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 36\n",
      "Loss for this step: Value(data=3.021010215643523, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 37\n",
      "Loss for this step: Value(data=3.4147641797927113, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 38\n",
      "Loss for this step: Value(data=4.254928011983901, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 39\n",
      "Loss for this step: Value(data=4.307058300332832, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 40\n",
      "Loss for this step: Value(data=3.366209558483738, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 41\n",
      "Loss for this step: Value(data=4.3356857550719425, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 42\n",
      "Loss for this step: Value(data=2.4204940674598814, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 43\n",
      "Loss for this step: Value(data=3.6930074935390804, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 44\n",
      "Loss for this step: Value(data=4.888054467074006, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 45\n",
      "Loss for this step: Value(data=3.881258025973116, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 46\n",
      "Loss for this step: Value(data=4.707143371410001, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 47\n",
      "Loss for this step: Value(data=5.130321984614836, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 48\n",
      "Loss for this step: Value(data=4.933096979572672, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 49\n",
      "Loss for this step: Value(data=4.025128080770126, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 50\n",
      "Loss for this step: Value(data=4.191882621671893, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 51\n",
      "Loss for this step: Value(data=3.6269925216560157, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 52\n",
      "Loss for this step: Value(data=2.845821210356843, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 53\n",
      "Loss for this step: Value(data=3.5852012434352876, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 54\n",
      "Loss for this step: Value(data=3.650618408913785, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 55\n",
      "Loss for this step: Value(data=2.653224067421002, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 56\n",
      "Loss for this step: Value(data=3.1902384706832456, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 57\n",
      "Loss for this step: Value(data=4.6638293164814355, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 58\n",
      "Loss for this step: Value(data=3.3657498249775144, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 59\n",
      "Loss for this step: Value(data=2.378909372427649, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 60\n",
      "Loss for this step: Value(data=3.6653699834001725, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 61\n",
      "Loss for this step: Value(data=4.7743460261968504, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 62\n",
      "Loss for this step: Value(data=5.532259517982321, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 63\n",
      "Loss for this step: Value(data=4.1348493031347795, grad=0)\n",
      "Accuracy: 0.375\n",
      "Epoch:5\n",
      "Step 1\n",
      "Loss for this step: Value(data=1.7369087062080932, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 2\n",
      "Loss for this step: Value(data=4.198596972587664, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 3\n",
      "Loss for this step: Value(data=4.27608924786177, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 4\n",
      "Loss for this step: Value(data=4.975112749078151, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 5\n",
      "Loss for this step: Value(data=3.6399436174186968, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 6\n",
      "Loss for this step: Value(data=5.241873887169991, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 7\n",
      "Loss for this step: Value(data=3.0599388679996813, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 8\n",
      "Loss for this step: Value(data=3.8760419823085535, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 9\n",
      "Loss for this step: Value(data=2.079868173704381, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 10\n",
      "Loss for this step: Value(data=1.5683673544167596, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 11\n",
      "Loss for this step: Value(data=2.3440839299729483, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 12\n",
      "Loss for this step: Value(data=2.7142296859797956, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 13\n",
      "Loss for this step: Value(data=3.5171092295748188, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 14\n",
      "Loss for this step: Value(data=2.4243599214133806, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 15\n",
      "Loss for this step: Value(data=2.933233152915033, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 16\n",
      "Loss for this step: Value(data=2.1139931159413337, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 17\n",
      "Loss for this step: Value(data=4.342737445806965, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 18\n",
      "Loss for this step: Value(data=5.849711907845537, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 19\n",
      "Loss for this step: Value(data=2.928247248289838, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 20\n",
      "Loss for this step: Value(data=2.768483392462446, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 21\n",
      "Loss for this step: Value(data=3.476577344308925, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 22\n",
      "Loss for this step: Value(data=3.300121348590919, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 23\n",
      "Loss for this step: Value(data=4.041459601803374, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 24\n",
      "Loss for this step: Value(data=3.6291173801523477, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 25\n",
      "Loss for this step: Value(data=3.265136011852903, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 26\n",
      "Loss for this step: Value(data=5.452638560099546, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 27\n",
      "Loss for this step: Value(data=3.354630765556486, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 28\n",
      "Loss for this step: Value(data=2.7268247887453674, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 29\n",
      "Loss for this step: Value(data=5.604282427988703, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 30\n",
      "Loss for this step: Value(data=2.771828962775116, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 31\n",
      "Loss for this step: Value(data=2.920101643916252, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 32\n",
      "Loss for this step: Value(data=3.7828473277032235, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 33\n",
      "Loss for this step: Value(data=3.102176614305031, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 34\n",
      "Loss for this step: Value(data=2.9035551265292145, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 35\n",
      "Loss for this step: Value(data=3.376950028648321, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 36\n",
      "Loss for this step: Value(data=4.000962975999877, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 37\n",
      "Loss for this step: Value(data=4.15987058955676, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 38\n",
      "Loss for this step: Value(data=3.408848689941122, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 39\n",
      "Loss for this step: Value(data=2.903334067033905, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 40\n",
      "Loss for this step: Value(data=2.941770153025248, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 41\n",
      "Loss for this step: Value(data=2.4369225233589114, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 42\n",
      "Loss for this step: Value(data=4.495988224706612, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 43\n",
      "Loss for this step: Value(data=2.861147949401653, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 44\n",
      "Loss for this step: Value(data=3.367161285953119, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 45\n",
      "Loss for this step: Value(data=5.9694958319789295, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 46\n",
      "Loss for this step: Value(data=3.5965081080639636, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 47\n",
      "Loss for this step: Value(data=3.808627773731286, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 48\n",
      "Loss for this step: Value(data=3.6451538347260204, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 49\n",
      "Loss for this step: Value(data=3.2410564716480756, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 50\n",
      "Loss for this step: Value(data=3.423722147137865, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 51\n",
      "Loss for this step: Value(data=2.8895979496428703, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 52\n",
      "Loss for this step: Value(data=2.395131700786227, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 53\n",
      "Loss for this step: Value(data=3.3647535761817737, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 54\n",
      "Loss for this step: Value(data=3.6226777789901967, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 55\n",
      "Loss for this step: Value(data=2.7978097481990987, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 56\n",
      "Loss for this step: Value(data=3.1856935262035977, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 57\n",
      "Loss for this step: Value(data=4.640956266357845, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 58\n",
      "Loss for this step: Value(data=3.383719344730806, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 59\n",
      "Loss for this step: Value(data=4.799719759024404, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 60\n",
      "Loss for this step: Value(data=3.1179341394388667, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 61\n",
      "Loss for this step: Value(data=4.0289903859888065, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 62\n",
      "Loss for this step: Value(data=4.410733092858035, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 63\n",
      "Loss for this step: Value(data=3.495099186707688, grad=0)\n",
      "Accuracy: 0.25\n",
      "Epoch:6\n",
      "Step 1\n",
      "Loss for this step: Value(data=3.8093856997861866, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 2\n",
      "Loss for this step: Value(data=2.8146617663179176, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 3\n",
      "Loss for this step: Value(data=3.082386807161675, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 4\n",
      "Loss for this step: Value(data=3.557314606731446, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 5\n",
      "Loss for this step: Value(data=4.9528229360855125, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 6\n",
      "Loss for this step: Value(data=2.455493604703836, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 7\n",
      "Loss for this step: Value(data=3.597140864184511, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 8\n",
      "Loss for this step: Value(data=3.530137639894773, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 9\n",
      "Loss for this step: Value(data=4.359502824999953, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 10\n",
      "Loss for this step: Value(data=3.980547699804693, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 11\n",
      "Loss for this step: Value(data=3.1840988026766976, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 12\n",
      "Loss for this step: Value(data=3.1995000836038163, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 13\n",
      "Loss for this step: Value(data=4.462784553462353, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 14\n",
      "Loss for this step: Value(data=4.337349785389478, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 15\n",
      "Loss for this step: Value(data=2.948891418260553, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 16\n",
      "Loss for this step: Value(data=4.265057201670277, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 17\n",
      "Loss for this step: Value(data=3.677267951034546, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 18\n",
      "Loss for this step: Value(data=3.7308653746286593, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 19\n",
      "Loss for this step: Value(data=3.215076561105894, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 20\n",
      "Loss for this step: Value(data=2.799100176137973, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 21\n",
      "Loss for this step: Value(data=4.0819248108194754, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 22\n",
      "Loss for this step: Value(data=2.4823715242560294, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 23\n",
      "Loss for this step: Value(data=3.032299824844045, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 24\n",
      "Loss for this step: Value(data=4.045784280934914, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 25\n",
      "Loss for this step: Value(data=2.82351066545351, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 26\n",
      "Loss for this step: Value(data=2.7104260444987203, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 27\n",
      "Loss for this step: Value(data=2.272652882901265, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 28\n",
      "Loss for this step: Value(data=1.5362946514724043, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 29\n",
      "Loss for this step: Value(data=3.0958752197367554, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 30\n",
      "Loss for this step: Value(data=2.9807316776525825, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 31\n",
      "Loss for this step: Value(data=2.4648799210301133, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 32\n",
      "Loss for this step: Value(data=2.459434887301284, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 33\n",
      "Loss for this step: Value(data=4.617213308326782, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 34\n",
      "Loss for this step: Value(data=2.487265541516621, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 35\n",
      "Loss for this step: Value(data=2.4022573529864846, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 36\n",
      "Loss for this step: Value(data=4.43006337324121, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 37\n",
      "Loss for this step: Value(data=2.0140585886603573, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 38\n",
      "Loss for this step: Value(data=1.9206692167754424, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 39\n",
      "Loss for this step: Value(data=2.619292328382333, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 40\n",
      "Loss for this step: Value(data=4.925770218577629, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 41\n",
      "Loss for this step: Value(data=5.707650075145521, grad=0)\n",
      "Accuracy: 0.0\n",
      "Step 42\n",
      "Loss for this step: Value(data=2.9378240060281255, grad=0)\n",
      "Accuracy: 0.5625\n",
      "Step 43\n",
      "Loss for this step: Value(data=4.79452365256983, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 44\n",
      "Loss for this step: Value(data=3.270377740459995, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 45\n",
      "Loss for this step: Value(data=2.9485473866585514, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 46\n",
      "Loss for this step: Value(data=1.7294782158012962, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 47\n",
      "Loss for this step: Value(data=2.374024597334378, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 48\n",
      "Loss for this step: Value(data=4.200351601064401, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 49\n",
      "Loss for this step: Value(data=2.756594619633587, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 50\n",
      "Loss for this step: Value(data=3.147783294676778, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 51\n",
      "Loss for this step: Value(data=3.3700267672908653, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 52\n",
      "Loss for this step: Value(data=3.4108267200657534, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 53\n",
      "Loss for this step: Value(data=4.938878780718925, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 54\n",
      "Loss for this step: Value(data=2.937991678275047, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 55\n",
      "Loss for this step: Value(data=3.1682959923969367, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 56\n",
      "Loss for this step: Value(data=2.5842708311751643, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 57\n",
      "Loss for this step: Value(data=2.33963889023161, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 58\n",
      "Loss for this step: Value(data=2.432290794522847, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 59\n",
      "Loss for this step: Value(data=2.1355987033053436, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 60\n",
      "Loss for this step: Value(data=1.5634671159873574, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 61\n",
      "Loss for this step: Value(data=2.7100337379030295, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 62\n",
      "Loss for this step: Value(data=3.864153850345392, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 63\n",
      "Loss for this step: Value(data=1.5188838293259956, grad=0)\n",
      "Accuracy: 0.5\n",
      "Epoch:7\n",
      "Step 1\n",
      "Loss for this step: Value(data=2.773450847204728, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 2\n",
      "Loss for this step: Value(data=3.2129279784966593, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 3\n",
      "Loss for this step: Value(data=3.1052861287767253, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 4\n",
      "Loss for this step: Value(data=2.213672551020752, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 5\n",
      "Loss for this step: Value(data=2.780555923340605, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 6\n",
      "Loss for this step: Value(data=2.6026450885067955, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 7\n",
      "Loss for this step: Value(data=2.3807376397473123, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 8\n",
      "Loss for this step: Value(data=3.157294820283418, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 9\n",
      "Loss for this step: Value(data=3.034082748383259, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 10\n",
      "Loss for this step: Value(data=2.1319281234251855, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 11\n",
      "Loss for this step: Value(data=3.103065302787833, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 12\n",
      "Loss for this step: Value(data=1.9963064635766918, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 13\n",
      "Loss for this step: Value(data=3.190586762010468, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 14\n",
      "Loss for this step: Value(data=2.701560049325677, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 15\n",
      "Loss for this step: Value(data=4.315727177997363, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 16\n",
      "Loss for this step: Value(data=1.9476737037786624, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 17\n",
      "Loss for this step: Value(data=2.700336685129764, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 18\n",
      "Loss for this step: Value(data=1.954914315687172, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 19\n",
      "Loss for this step: Value(data=2.2759831228963776, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 20\n",
      "Loss for this step: Value(data=4.978839650941237, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 21\n",
      "Loss for this step: Value(data=3.3595542705551997, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 22\n",
      "Loss for this step: Value(data=2.563952349896104, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 23\n",
      "Loss for this step: Value(data=2.9903799620670304, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 24\n",
      "Loss for this step: Value(data=2.78800047498161, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 25\n",
      "Loss for this step: Value(data=2.2623734860583142, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 26\n",
      "Loss for this step: Value(data=2.68445356403375, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 27\n",
      "Loss for this step: Value(data=2.7147064484389576, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 28\n",
      "Loss for this step: Value(data=2.3514069304085523, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 29\n",
      "Loss for this step: Value(data=4.385410966313663, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 30\n",
      "Loss for this step: Value(data=2.6673041821128374, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 31\n",
      "Loss for this step: Value(data=2.8986075212016247, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 32\n",
      "Loss for this step: Value(data=4.345993227029865, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 33\n",
      "Loss for this step: Value(data=3.9946415719925303, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 34\n",
      "Loss for this step: Value(data=2.428944757345904, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 35\n",
      "Loss for this step: Value(data=2.9890722811290416, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 36\n",
      "Loss for this step: Value(data=3.801246569371022, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 37\n",
      "Loss for this step: Value(data=3.1800526402138622, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 38\n",
      "Loss for this step: Value(data=1.972067148244528, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 39\n",
      "Loss for this step: Value(data=4.630172927898336, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 40\n",
      "Loss for this step: Value(data=4.437235206598441, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 41\n",
      "Loss for this step: Value(data=4.856955109725499, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 42\n",
      "Loss for this step: Value(data=2.9386750332147753, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 43\n",
      "Loss for this step: Value(data=2.696907484876455, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 44\n",
      "Loss for this step: Value(data=2.3958025813708383, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 45\n",
      "Loss for this step: Value(data=2.724263659737856, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 46\n",
      "Loss for this step: Value(data=3.7979317992395907, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 47\n",
      "Loss for this step: Value(data=2.722906669913079, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 48\n",
      "Loss for this step: Value(data=3.9698160141626113, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 49\n",
      "Loss for this step: Value(data=4.130711220801538, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 50\n",
      "Loss for this step: Value(data=2.771658052395303, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 51\n",
      "Loss for this step: Value(data=2.4719732731546142, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 52\n",
      "Loss for this step: Value(data=3.4826803173362624, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 53\n",
      "Loss for this step: Value(data=2.3622637399350546, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 54\n",
      "Loss for this step: Value(data=3.6401368266239276, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 55\n",
      "Loss for this step: Value(data=3.2586000366865124, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 56\n",
      "Loss for this step: Value(data=2.217203586221478, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 57\n",
      "Loss for this step: Value(data=1.801695661048044, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 58\n",
      "Loss for this step: Value(data=3.7868401030609, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 59\n",
      "Loss for this step: Value(data=4.2105460691327785, grad=0)\n",
      "Accuracy: 0.0\n",
      "Step 60\n",
      "Loss for this step: Value(data=2.1793325568927027, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 61\n",
      "Loss for this step: Value(data=2.1932692381612218, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 62\n",
      "Loss for this step: Value(data=3.0409365629935734, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 63\n",
      "Loss for this step: Value(data=2.1423335324714246, grad=0)\n",
      "Accuracy: 0.125\n",
      "Epoch:8\n",
      "Step 1\n",
      "Loss for this step: Value(data=3.3550244665511872, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 2\n",
      "Loss for this step: Value(data=3.221761857970301, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 3\n",
      "Loss for this step: Value(data=3.019903000502227, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 4\n",
      "Loss for this step: Value(data=2.627662661023855, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 5\n",
      "Loss for this step: Value(data=2.2735919883025786, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 6\n",
      "Loss for this step: Value(data=3.5204126153135027, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 7\n",
      "Loss for this step: Value(data=2.8006409700439665, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 8\n",
      "Loss for this step: Value(data=2.9025515069347763, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 9\n",
      "Loss for this step: Value(data=2.283437641250754, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 10\n",
      "Loss for this step: Value(data=2.2362464158678983, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 11\n",
      "Loss for this step: Value(data=3.5861371009912455, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 12\n",
      "Loss for this step: Value(data=2.679722043363759, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 13\n",
      "Loss for this step: Value(data=4.8404587322702755, grad=0)\n",
      "Accuracy: 0.0625\n",
      "Step 14\n",
      "Loss for this step: Value(data=3.701480153319246, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 15\n",
      "Loss for this step: Value(data=2.783610067830586, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 16\n",
      "Loss for this step: Value(data=3.0889288490903173, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 17\n",
      "Loss for this step: Value(data=1.8061600555182586, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 18\n",
      "Loss for this step: Value(data=2.558484396938311, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 19\n",
      "Loss for this step: Value(data=3.385316660645033, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 20\n",
      "Loss for this step: Value(data=2.385550699218513, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 21\n",
      "Loss for this step: Value(data=2.808126315485894, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 22\n",
      "Loss for this step: Value(data=3.083341152756989, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 23\n",
      "Loss for this step: Value(data=2.1523618257518393, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 24\n",
      "Loss for this step: Value(data=2.928637431511292, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 25\n",
      "Loss for this step: Value(data=3.502071393397545, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 26\n",
      "Loss for this step: Value(data=2.3152025178273803, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 27\n",
      "Loss for this step: Value(data=1.8364475702811671, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 28\n",
      "Loss for this step: Value(data=3.604328119801367, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 29\n",
      "Loss for this step: Value(data=3.6432369264106175, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 30\n",
      "Loss for this step: Value(data=2.0802926954514533, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 31\n",
      "Loss for this step: Value(data=3.2104983130112013, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 32\n",
      "Loss for this step: Value(data=1.867528088454486, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 33\n",
      "Loss for this step: Value(data=2.819029813198022, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 34\n",
      "Loss for this step: Value(data=1.3818573631826492, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 35\n",
      "Loss for this step: Value(data=3.30994675878872, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 36\n",
      "Loss for this step: Value(data=4.250132397739398, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 37\n",
      "Loss for this step: Value(data=3.987299800913461, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 38\n",
      "Loss for this step: Value(data=2.9284751953684895, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 39\n",
      "Loss for this step: Value(data=3.432126638427, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 40\n",
      "Loss for this step: Value(data=3.0881678499820038, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 41\n",
      "Loss for this step: Value(data=3.7658498298105783, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 42\n",
      "Loss for this step: Value(data=2.8243509329295815, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 43\n",
      "Loss for this step: Value(data=3.602972858289396, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 44\n",
      "Loss for this step: Value(data=2.3275503759328506, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 45\n",
      "Loss for this step: Value(data=3.0192667050916397, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 46\n",
      "Loss for this step: Value(data=2.7172212139852996, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 47\n",
      "Loss for this step: Value(data=2.7769397698141494, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 48\n",
      "Loss for this step: Value(data=2.0168457226766083, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 49\n",
      "Loss for this step: Value(data=2.5868199029029517, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 50\n",
      "Loss for this step: Value(data=2.0882878520511845, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 51\n",
      "Loss for this step: Value(data=2.3872035544524266, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 52\n",
      "Loss for this step: Value(data=2.291053172889932, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 53\n",
      "Loss for this step: Value(data=3.6852769919557415, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 54\n",
      "Loss for this step: Value(data=2.988940560367397, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 55\n",
      "Loss for this step: Value(data=1.1607995953900578, grad=0)\n",
      "Accuracy: 0.5625\n",
      "Step 56\n",
      "Loss for this step: Value(data=3.272780935240188, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 57\n",
      "Loss for this step: Value(data=2.7761585838641554, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 58\n",
      "Loss for this step: Value(data=1.7868310282829665, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 59\n",
      "Loss for this step: Value(data=3.36321730068443, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 60\n",
      "Loss for this step: Value(data=3.724395313746508, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 61\n",
      "Loss for this step: Value(data=2.8755435413659822, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 62\n",
      "Loss for this step: Value(data=2.943999416050256, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 63\n",
      "Loss for this step: Value(data=1.9433480349505425, grad=0)\n",
      "Accuracy: 0.25\n",
      "Epoch:9\n",
      "Step 1\n",
      "Loss for this step: Value(data=1.9737249571696485, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 2\n",
      "Loss for this step: Value(data=3.069471474268734, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 3\n",
      "Loss for this step: Value(data=3.020179707072529, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 4\n",
      "Loss for this step: Value(data=2.0305518947078802, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 5\n",
      "Loss for this step: Value(data=1.806570018411256, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 6\n",
      "Loss for this step: Value(data=2.449893886936002, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 7\n",
      "Loss for this step: Value(data=3.5015730918540013, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 8\n",
      "Loss for this step: Value(data=3.2370299778990046, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 9\n",
      "Loss for this step: Value(data=2.844414916865617, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 10\n",
      "Loss for this step: Value(data=2.430668154287582, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 11\n",
      "Loss for this step: Value(data=2.8253621506127646, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 12\n",
      "Loss for this step: Value(data=3.195774458725005, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 13\n",
      "Loss for this step: Value(data=2.255718523640768, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 14\n",
      "Loss for this step: Value(data=3.5971752700854385, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 15\n",
      "Loss for this step: Value(data=2.6602831144206345, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 16\n",
      "Loss for this step: Value(data=1.726454136822793, grad=0)\n",
      "Accuracy: 0.5\n",
      "Step 17\n",
      "Loss for this step: Value(data=3.272125891982034, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 18\n",
      "Loss for this step: Value(data=4.9989069674532605, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 19\n",
      "Loss for this step: Value(data=2.0246601099729684, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 20\n",
      "Loss for this step: Value(data=3.1057900909561584, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 21\n",
      "Loss for this step: Value(data=3.486975506261806, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 22\n",
      "Loss for this step: Value(data=2.2063008404030446, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 23\n",
      "Loss for this step: Value(data=2.7640406609476194, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 24\n",
      "Loss for this step: Value(data=3.2907903322963543, grad=0)\n",
      "Accuracy: 0.125\n",
      "Step 25\n",
      "Loss for this step: Value(data=1.7062368935399124, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 26\n",
      "Loss for this step: Value(data=2.83212713920331, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 27\n",
      "Loss for this step: Value(data=3.311483803792092, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 28\n",
      "Loss for this step: Value(data=3.2645135762635955, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 29\n",
      "Loss for this step: Value(data=2.9324080640768435, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 30\n",
      "Loss for this step: Value(data=2.571263514608585, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 31\n",
      "Loss for this step: Value(data=1.6385523385321352, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 32\n",
      "Loss for this step: Value(data=2.4209210618999637, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 33\n",
      "Loss for this step: Value(data=1.7311787406873684, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 34\n",
      "Loss for this step: Value(data=2.9324705364113193, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 35\n",
      "Loss for this step: Value(data=3.1475411801592603, grad=0)\n",
      "Accuracy: 0.1875\n",
      "Step 36\n",
      "Loss for this step: Value(data=2.5778184376805346, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 37\n",
      "Loss for this step: Value(data=1.9247714630138182, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 38\n",
      "Loss for this step: Value(data=3.2577277365521202, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 39\n",
      "Loss for this step: Value(data=2.363711433237073, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 40\n",
      "Loss for this step: Value(data=2.2892947409356332, grad=0)\n",
      "Accuracy: 0.4375\n",
      "Step 41\n",
      "Loss for this step: Value(data=3.2358586565588707, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 42\n",
      "Loss for this step: Value(data=2.9644125696257677, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 43\n",
      "Loss for this step: Value(data=2.2488446632887795, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 44\n",
      "Loss for this step: Value(data=3.716256117321899, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 45\n",
      "Loss for this step: Value(data=3.002284480239602, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 46\n",
      "Loss for this step: Value(data=4.151615625775851, grad=0)\n",
      "Accuracy: 0.3125\n",
      "Step 47\n",
      "Loss for this step: Value(data=3.325833875851583, grad=0)\n",
      "Accuracy: 0.3125\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "no_of_steps = math.ceil(len(X_train)/batch_size)\n",
    "epochs = 10\n",
    "\n",
    "for _ in range(epochs):\n",
    "    print(f'Epoch:{_+1}')\n",
    "\n",
    "    combined = list(zip(X_train, y_train))\n",
    "    random.shuffle(combined)\n",
    "    X_train, y_train = zip(*combined)\n",
    "    \n",
    "    for i in range(no_of_steps):\n",
    "        X_batch = X_train[(i*batch_size):((i+1)*batch_size)]\n",
    "        y_batch = y_train[(i*batch_size):((i+1)*batch_size)]\n",
    "\n",
    "        input = [list(map(Value, X_list)) for X_list in X_batch]\n",
    "\n",
    "        forward = list(map(model, input))\n",
    "        loss_lst = [cross_entropy_loss(prediction, ground_truth) for prediction, ground_truth in zip(forward, y_batch)]\n",
    "        average_loss = sum(loss_lst) / len(loss_lst)\n",
    "\n",
    "        forward = [[num.data for num in sublist] for sublist in forward]\n",
    "        accuracy = [my_list.index(max(my_list)) for my_list in forward]\n",
    "        accuracy = [1 if acc == y else 0 for acc,y in zip(accuracy,y_batch)]\n",
    "        accuracy = sum(accuracy) / len(accuracy) \n",
    "        \n",
    "\n",
    "        print(f'Step {i+1}')\n",
    "        print('Loss for this step:', average_loss)\n",
    "        print('Accuracy:', accuracy)\n",
    "    \n",
    "        \n",
    "        model.zero_grad()\n",
    "        average_loss.backward()\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.data -= 0.001 * p.grad\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shahz\\Desktop\\Python Projects\\nn-from-scratch\\mnist-notebook.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shahz/Desktop/Python%20Projects/nn-from-scratch/mnist-notebook.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m weights \u001b[39m=\u001b[39m [n\u001b[39m.\u001b[39mdata \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters()]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shahz/Desktop/Python%20Projects/nn-from-scratch/mnist-notebook.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mweights/mnist_model_weights_64.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shahz/Desktop/Python%20Projects/nn-from-scratch/mnist-notebook.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Use the dump method of the pickle module to save the list to the file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shahz/Desktop/Python%20Projects/nn-from-scratch/mnist-notebook.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(weights, file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "weights = [n.data for n in model.parameters()]\n",
    "with open(\"weights/mnist_model_weights_32.pkl\", \"wb\") as file:\n",
    "    # Use the dump method of the pickle module to save the list to the file\n",
    "    pickle.dump(weights, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"weights/mnist_model_weights_32.pkl\", \"rb\") as file:\n",
    "    # Use the dump method of the pickle module to save the list to the file\n",
    "    weights = pickle.load(file)\n",
    "\n",
    "model.load_weights(weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfrom validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Loss for this step: Value(data=3.816225268411391, grad=0)\n",
      "Accuracy: 0.375\n",
      "Step 2\n",
      "Loss for this step: Value(data=4.171489769272255, grad=0)\n",
      "Accuracy: 0.25\n",
      "Step 3\n",
      "Loss for this step: Value(data=3.274247063940989, grad=0)\n",
      "Accuracy: 0.125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shahz\\Desktop\\Python Projects\\nn-from-scratch\\mnist-notebook.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shahz/Desktop/Python%20Projects/nn-from-scratch/mnist-notebook.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_batch \u001b[39m=\u001b[39m y_test[(i\u001b[39m*\u001b[39mbatch_size):((i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shahz/Desktop/Python%20Projects/nn-from-scratch/mnist-notebook.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(Value, X_list)) \u001b[39mfor\u001b[39;00m X_list \u001b[39min\u001b[39;00m X_batch]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shahz/Desktop/Python%20Projects/nn-from-scratch/mnist-notebook.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m forward \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(model, \u001b[39minput\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shahz/Desktop/Python%20Projects/nn-from-scratch/mnist-notebook.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss_lst \u001b[39m=\u001b[39m [cross_entropy_loss(prediction, ground_truth) \u001b[39mfor\u001b[39;00m prediction, ground_truth \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(forward, y_batch)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shahz/Desktop/Python%20Projects/nn-from-scratch/mnist-notebook.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m average_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(loss_lst) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(loss_lst)\n",
      "File \u001b[1;32mc:\\Users\\shahz\\Desktop\\Python Projects\\nn-from-scratch\\autodiff\\nn.py:65\u001b[0m, in \u001b[0;36mMLP.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     64\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 65\u001b[0m         x \u001b[39m=\u001b[39m layer(x)\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\shahz\\Desktop\\Python Projects\\nn-from-scratch\\autodiff\\nn.py:47\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 47\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m n: n(x), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneurons))\n\u001b[0;32m     48\u001b[0m     \u001b[39mreturn\u001b[39;00m out[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\shahz\\Desktop\\Python Projects\\nn-from-scratch\\autodiff\\nn.py:47\u001b[0m, in \u001b[0;36mLayer.__call__.<locals>.<lambda>\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 47\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m n: n(x), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneurons))\n\u001b[0;32m     48\u001b[0m     \u001b[39mreturn\u001b[39;00m out[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\shahz\\Desktop\\Python Projects\\nn-from-scratch\\autodiff\\nn.py:24\u001b[0m, in \u001b[0;36mNeuron.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([weights_i \u001b[39m*\u001b[39m x_i \u001b[39mfor\u001b[39;00m weights_i, x_i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights, x)], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n\u001b[0;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_relu:\n\u001b[0;32m     27\u001b[0m         \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39mrelu()\n",
      "File \u001b[1;32mc:\\Users\\shahz\\Desktop\\Python Projects\\nn-from-scratch\\autodiff\\nn.py:24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([weights_i \u001b[39m*\u001b[39;49m x_i \u001b[39mfor\u001b[39;00m weights_i, x_i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights, x)], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n\u001b[0;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_relu:\n\u001b[0;32m     27\u001b[0m         \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39mrelu()\n",
      "File \u001b[1;32mc:\\Users\\shahz\\Desktop\\Python Projects\\nn-from-scratch\\autodiff\\core.py:36\u001b[0m, in \u001b[0;36mValue.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mgrad \u001b[39m*\u001b[39m other\u001b[39m.\u001b[39mdata\n\u001b[0;32m     34\u001b[0m     other\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mgrad \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\n\u001b[1;32m---> 36\u001b[0m out\u001b[39m.\u001b[39m_backward \u001b[39m=\u001b[39m _backward\n\u001b[0;32m     38\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "no_of_steps = math.ceil(len(X_train)/batch_size)\n",
    "epochs = 10\n",
    "total_loss = 0\n",
    "    \n",
    "for i in range(no_of_steps):\n",
    "    X_batch = X_test[(i*batch_size):((i+1)*batch_size)]\n",
    "    y_batch = y_test[(i*batch_size):((i+1)*batch_size)]\n",
    "\n",
    "    input = [list(map(Value, X_list)) for X_list in X_batch]\n",
    "\n",
    "    forward = list(map(model, input))\n",
    "    \n",
    "    loss_lst = [cross_entropy_loss(prediction, ground_truth) for prediction, ground_truth in zip(forward, y_batch)]\n",
    "    average_loss = sum(loss_lst) / len(loss_lst)\n",
    "    total_loss += average_loss\n",
    "\n",
    "    forward = [[num.data for num in sublist] for sublist in forward]\n",
    "    accuracy = [my_list.index(max(my_list)) for my_list in forward]\n",
    "    accuracy = [1 if acc == y else 0 for acc,y in zip(accuracy,y_batch)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "\n",
    "    print(f'Step {i+1}')\n",
    "    print('Loss for this step:', average_loss)\n",
    "    print('Accuracy:', accuracy)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Value(data=0.09424117365933707, grad=0),\n",
       "  Value(data=0.4184609605078055, grad=0),\n",
       "  Value(data=-0.664599063941032, grad=0),\n",
       "  Value(data=-1.583431277894505, grad=0),\n",
       "  Value(data=-0.017398324827849143, grad=0),\n",
       "  Value(data=-0.7167853363564802, grad=0),\n",
       "  Value(data=-0.4549307072219745, grad=0),\n",
       "  Value(data=1.2038332274594987, grad=0),\n",
       "  Value(data=0.373443543342243, grad=0),\n",
       "  Value(data=0.8276204631562917, grad=0)],\n",
       " [Value(data=-2.1411602271465524, grad=0),\n",
       "  Value(data=9.342420766679076, grad=0),\n",
       "  Value(data=1.426822689023521, grad=0),\n",
       "  Value(data=1.0807890493819232, grad=0),\n",
       "  Value(data=1.525374580104971, grad=0),\n",
       "  Value(data=-2.7366710983190337, grad=0),\n",
       "  Value(data=-3.1013386643815863, grad=0),\n",
       "  Value(data=-7.525030972078762, grad=0),\n",
       "  Value(data=-4.048029728097313, grad=0),\n",
       "  Value(data=-5.154371912577857, grad=0)],\n",
       " [Value(data=-0.09159542030479202, grad=0),\n",
       "  Value(data=6.057653340343903, grad=0),\n",
       "  Value(data=-0.8909368096575161, grad=0),\n",
       "  Value(data=3.5007844887938986, grad=0),\n",
       "  Value(data=3.7670957157016156, grad=0),\n",
       "  Value(data=2.785540893347297, grad=0),\n",
       "  Value(data=-1.4174161423345775, grad=0),\n",
       "  Value(data=-2.1144482987143767, grad=0),\n",
       "  Value(data=-1.701174886678726, grad=0),\n",
       "  Value(data=-2.7923579206408284, grad=0)],\n",
       " [Value(data=0.022787071091541974, grad=0),\n",
       "  Value(data=-0.06794451262116072, grad=0),\n",
       "  Value(data=-0.02291231521074643, grad=0),\n",
       "  Value(data=0.025861598215127055, grad=0),\n",
       "  Value(data=-0.03349018423849103, grad=0),\n",
       "  Value(data=0.03171775816031195, grad=0),\n",
       "  Value(data=-0.029382200323463108, grad=0),\n",
       "  Value(data=0.026757418764064983, grad=0),\n",
       "  Value(data=0.0002677626151923731, grad=0),\n",
       "  Value(data=0.04518976147224434, grad=0)],\n",
       " [Value(data=-7.190850118776851, grad=0),\n",
       "  Value(data=7.904008371580309, grad=0),\n",
       "  Value(data=3.5942784904048968, grad=0),\n",
       "  Value(data=4.057915906987867, grad=0),\n",
       "  Value(data=-0.6248222279906837, grad=0),\n",
       "  Value(data=-14.233431123624037, grad=0),\n",
       "  Value(data=10.371019200386199, grad=0),\n",
       "  Value(data=9.45490158886199, grad=0),\n",
       "  Value(data=-7.9224932479431205, grad=0),\n",
       "  Value(data=8.630434808995545, grad=0)],\n",
       " [Value(data=1.2649443938099392, grad=0),\n",
       "  Value(data=6.003892802234251, grad=0),\n",
       "  Value(data=-3.351010802596842, grad=0),\n",
       "  Value(data=2.184747599287164, grad=0),\n",
       "  Value(data=4.48368987240136, grad=0),\n",
       "  Value(data=2.939848175779818, grad=0),\n",
       "  Value(data=-5.829401591713614, grad=0),\n",
       "  Value(data=-2.995642840995498, grad=0),\n",
       "  Value(data=-0.933522597877128, grad=0),\n",
       "  Value(data=-7.269959834171237, grad=0)],\n",
       " [Value(data=-2.426991192383619, grad=0),\n",
       "  Value(data=1.7423312976876464, grad=0),\n",
       "  Value(data=0.07984435110625462, grad=0),\n",
       "  Value(data=0.975675486946276, grad=0),\n",
       "  Value(data=2.399323962553996, grad=0),\n",
       "  Value(data=1.518865244715198, grad=0),\n",
       "  Value(data=0.503070890769815, grad=0),\n",
       "  Value(data=0.9947432404149903, grad=0),\n",
       "  Value(data=-0.4249225941925827, grad=0),\n",
       "  Value(data=-0.222778265933046, grad=0)],\n",
       " [Value(data=-4.559563604764934, grad=0),\n",
       "  Value(data=9.19248675454487, grad=0),\n",
       "  Value(data=1.5163378072914415, grad=0),\n",
       "  Value(data=-2.534886944136303, grad=0),\n",
       "  Value(data=-4.612623598560913, grad=0),\n",
       "  Value(data=-8.315725143171406, grad=0),\n",
       "  Value(data=3.4352836337154473, grad=0),\n",
       "  Value(data=5.655535527668595, grad=0),\n",
       "  Value(data=-2.0303726011374756, grad=0),\n",
       "  Value(data=1.7926469488586598, grad=0)],\n",
       " [Value(data=-0.3234385056559743, grad=0),\n",
       "  Value(data=-1.8432896154770881, grad=0),\n",
       "  Value(data=0.44158407007113654, grad=0),\n",
       "  Value(data=-2.2936490332711843, grad=0),\n",
       "  Value(data=3.2853497055311354, grad=0),\n",
       "  Value(data=-3.1725937270174045, grad=0),\n",
       "  Value(data=2.4557965021964465, grad=0),\n",
       "  Value(data=0.4595714615518507, grad=0),\n",
       "  Value(data=-0.8440187426585999, grad=0),\n",
       "  Value(data=-1.7345974896584093, grad=0)],\n",
       " [Value(data=-1.1184133455405652, grad=0),\n",
       "  Value(data=-0.9326429519456008, grad=0),\n",
       "  Value(data=-2.344616354560924, grad=0),\n",
       "  Value(data=-2.426355429259345, grad=0),\n",
       "  Value(data=-0.8521162925088733, grad=0),\n",
       "  Value(data=-0.6981259857034142, grad=0),\n",
       "  Value(data=0.5727391944139825, grad=0),\n",
       "  Value(data=1.7292309336057095, grad=0),\n",
       "  Value(data=0.0567673558762668, grad=0),\n",
       "  Value(data=1.051458522395264, grad=0)],\n",
       " [Value(data=-1.3639096253912004, grad=0),\n",
       "  Value(data=1.7227740976844919, grad=0),\n",
       "  Value(data=2.214203041869306, grad=0),\n",
       "  Value(data=1.4986487404331195, grad=0),\n",
       "  Value(data=-1.9620299401627928, grad=0),\n",
       "  Value(data=0.2693098684070186, grad=0),\n",
       "  Value(data=1.4688968020431534, grad=0),\n",
       "  Value(data=-0.4218760441713982, grad=0),\n",
       "  Value(data=-1.3810605007394297, grad=0),\n",
       "  Value(data=-0.7678511508512437, grad=0)],\n",
       " [Value(data=-1.2695483167465251, grad=0),\n",
       "  Value(data=3.171241308726775, grad=0),\n",
       "  Value(data=-4.350058690493106, grad=0),\n",
       "  Value(data=1.079665770255785, grad=0),\n",
       "  Value(data=3.5476248400710904, grad=0),\n",
       "  Value(data=0.35723673618693685, grad=0),\n",
       "  Value(data=-0.8969590581612401, grad=0),\n",
       "  Value(data=-2.5803847017363766, grad=0),\n",
       "  Value(data=-1.8963768402977446, grad=0),\n",
       "  Value(data=-4.859197187679032, grad=0)],\n",
       " [Value(data=0.022787071091541974, grad=0),\n",
       "  Value(data=-0.06794451262116072, grad=0),\n",
       "  Value(data=-0.02291231521074643, grad=0),\n",
       "  Value(data=0.025861598215127055, grad=0),\n",
       "  Value(data=-0.03349018423849103, grad=0),\n",
       "  Value(data=0.03171775816031195, grad=0),\n",
       "  Value(data=-0.029382200323463108, grad=0),\n",
       "  Value(data=0.026757418764064983, grad=0),\n",
       "  Value(data=0.0002677626151923731, grad=0),\n",
       "  Value(data=0.04518976147224434, grad=0)],\n",
       " [Value(data=-0.641837221837908, grad=0),\n",
       "  Value(data=-0.5755959904057186, grad=0),\n",
       "  Value(data=-0.9957631732705499, grad=0),\n",
       "  Value(data=-0.21441436789030327, grad=0),\n",
       "  Value(data=0.9432179904053051, grad=0),\n",
       "  Value(data=0.18743591736564258, grad=0),\n",
       "  Value(data=0.01725698583784607, grad=0),\n",
       "  Value(data=0.35814810393947927, grad=0),\n",
       "  Value(data=0.025837190075538377, grad=0),\n",
       "  Value(data=-0.0012982678290999524, grad=0)],\n",
       " [Value(data=-1.5245993921997145, grad=0),\n",
       "  Value(data=3.4654053918895285, grad=0),\n",
       "  Value(data=0.36190319590413983, grad=0),\n",
       "  Value(data=-1.2587188773538145, grad=0),\n",
       "  Value(data=0.8567192497537386, grad=0),\n",
       "  Value(data=-0.7973998828807857, grad=0),\n",
       "  Value(data=0.1548929772640397, grad=0),\n",
       "  Value(data=1.835547419407454, grad=0),\n",
       "  Value(data=2.7153166671259656, grad=0),\n",
       "  Value(data=0.6139884471090745, grad=0)],\n",
       " [Value(data=-2.9120999792111264, grad=0),\n",
       "  Value(data=5.49806126835202, grad=0),\n",
       "  Value(data=4.744718146881601, grad=0),\n",
       "  Value(data=3.5862409151048475, grad=0),\n",
       "  Value(data=-6.1013862427802925, grad=0),\n",
       "  Value(data=0.9899995699562695, grad=0),\n",
       "  Value(data=2.9828798019708205, grad=0),\n",
       "  Value(data=-2.026343861478265, grad=0),\n",
       "  Value(data=-3.6009271575891404, grad=0),\n",
       "  Value(data=-0.7636183163308511, grad=0)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.09424117365933707,\n",
       "  0.4184609605078055,\n",
       "  -0.664599063941032,\n",
       "  -1.583431277894505,\n",
       "  -0.017398324827849143,\n",
       "  -0.7167853363564802,\n",
       "  -0.4549307072219745,\n",
       "  1.2038332274594987,\n",
       "  0.373443543342243,\n",
       "  0.8276204631562917],\n",
       " [-2.1411602271465524,\n",
       "  9.342420766679076,\n",
       "  1.426822689023521,\n",
       "  1.0807890493819232,\n",
       "  1.525374580104971,\n",
       "  -2.7366710983190337,\n",
       "  -3.1013386643815863,\n",
       "  -7.525030972078762,\n",
       "  -4.048029728097313,\n",
       "  -5.154371912577857],\n",
       " [-0.09159542030479202,\n",
       "  6.057653340343903,\n",
       "  -0.8909368096575161,\n",
       "  3.5007844887938986,\n",
       "  3.7670957157016156,\n",
       "  2.785540893347297,\n",
       "  -1.4174161423345775,\n",
       "  -2.1144482987143767,\n",
       "  -1.701174886678726,\n",
       "  -2.7923579206408284],\n",
       " [0.022787071091541974,\n",
       "  -0.06794451262116072,\n",
       "  -0.02291231521074643,\n",
       "  0.025861598215127055,\n",
       "  -0.03349018423849103,\n",
       "  0.03171775816031195,\n",
       "  -0.029382200323463108,\n",
       "  0.026757418764064983,\n",
       "  0.0002677626151923731,\n",
       "  0.04518976147224434],\n",
       " [-7.190850118776851,\n",
       "  7.904008371580309,\n",
       "  3.5942784904048968,\n",
       "  4.057915906987867,\n",
       "  -0.6248222279906837,\n",
       "  -14.233431123624037,\n",
       "  10.371019200386199,\n",
       "  9.45490158886199,\n",
       "  -7.9224932479431205,\n",
       "  8.630434808995545],\n",
       " [1.2649443938099392,\n",
       "  6.003892802234251,\n",
       "  -3.351010802596842,\n",
       "  2.184747599287164,\n",
       "  4.48368987240136,\n",
       "  2.939848175779818,\n",
       "  -5.829401591713614,\n",
       "  -2.995642840995498,\n",
       "  -0.933522597877128,\n",
       "  -7.269959834171237],\n",
       " [-2.426991192383619,\n",
       "  1.7423312976876464,\n",
       "  0.07984435110625462,\n",
       "  0.975675486946276,\n",
       "  2.399323962553996,\n",
       "  1.518865244715198,\n",
       "  0.503070890769815,\n",
       "  0.9947432404149903,\n",
       "  -0.4249225941925827,\n",
       "  -0.222778265933046],\n",
       " [-4.559563604764934,\n",
       "  9.19248675454487,\n",
       "  1.5163378072914415,\n",
       "  -2.534886944136303,\n",
       "  -4.612623598560913,\n",
       "  -8.315725143171406,\n",
       "  3.4352836337154473,\n",
       "  5.655535527668595,\n",
       "  -2.0303726011374756,\n",
       "  1.7926469488586598],\n",
       " [-0.3234385056559743,\n",
       "  -1.8432896154770881,\n",
       "  0.44158407007113654,\n",
       "  -2.2936490332711843,\n",
       "  3.2853497055311354,\n",
       "  -3.1725937270174045,\n",
       "  2.4557965021964465,\n",
       "  0.4595714615518507,\n",
       "  -0.8440187426585999,\n",
       "  -1.7345974896584093],\n",
       " [-1.1184133455405652,\n",
       "  -0.9326429519456008,\n",
       "  -2.344616354560924,\n",
       "  -2.426355429259345,\n",
       "  -0.8521162925088733,\n",
       "  -0.6981259857034142,\n",
       "  0.5727391944139825,\n",
       "  1.7292309336057095,\n",
       "  0.0567673558762668,\n",
       "  1.051458522395264],\n",
       " [-1.3639096253912004,\n",
       "  1.7227740976844919,\n",
       "  2.214203041869306,\n",
       "  1.4986487404331195,\n",
       "  -1.9620299401627928,\n",
       "  0.2693098684070186,\n",
       "  1.4688968020431534,\n",
       "  -0.4218760441713982,\n",
       "  -1.3810605007394297,\n",
       "  -0.7678511508512437],\n",
       " [-1.2695483167465251,\n",
       "  3.171241308726775,\n",
       "  -4.350058690493106,\n",
       "  1.079665770255785,\n",
       "  3.5476248400710904,\n",
       "  0.35723673618693685,\n",
       "  -0.8969590581612401,\n",
       "  -2.5803847017363766,\n",
       "  -1.8963768402977446,\n",
       "  -4.859197187679032],\n",
       " [0.022787071091541974,\n",
       "  -0.06794451262116072,\n",
       "  -0.02291231521074643,\n",
       "  0.025861598215127055,\n",
       "  -0.03349018423849103,\n",
       "  0.03171775816031195,\n",
       "  -0.029382200323463108,\n",
       "  0.026757418764064983,\n",
       "  0.0002677626151923731,\n",
       "  0.04518976147224434],\n",
       " [-0.641837221837908,\n",
       "  -0.5755959904057186,\n",
       "  -0.9957631732705499,\n",
       "  -0.21441436789030327,\n",
       "  0.9432179904053051,\n",
       "  0.18743591736564258,\n",
       "  0.01725698583784607,\n",
       "  0.35814810393947927,\n",
       "  0.025837190075538377,\n",
       "  -0.0012982678290999524],\n",
       " [-1.5245993921997145,\n",
       "  3.4654053918895285,\n",
       "  0.36190319590413983,\n",
       "  -1.2587188773538145,\n",
       "  0.8567192497537386,\n",
       "  -0.7973998828807857,\n",
       "  0.1548929772640397,\n",
       "  1.835547419407454,\n",
       "  2.7153166671259656,\n",
       "  0.6139884471090745],\n",
       " [-2.9120999792111264,\n",
       "  5.49806126835202,\n",
       "  4.744718146881601,\n",
       "  3.5862409151048475,\n",
       "  -6.1013862427802925,\n",
       "  0.9899995699562695,\n",
       "  2.9828798019708205,\n",
       "  -2.026343861478265,\n",
       "  -3.6009271575891404,\n",
       "  -0.7636183163308511]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[num.data for num in sublist] for sublist in forward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
